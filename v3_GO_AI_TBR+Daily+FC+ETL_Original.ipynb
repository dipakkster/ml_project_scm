{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 50px, width 45px\"  src=\"https://miro.medium.com/max/1280/1*tHXPVLP294z8dcZwkL3wHw.png\" width=\"250\" height=\"50\" > <br/><br/>\n",
    "## TRON Bypass Rate Model ETL (Daily, Site Level)\n",
    " \n",
    "**Team: RST-A**<br/>\n",
    "**Date**: Q1 2023<br/>\n",
    "\n",
    "<hr style=\"height:2pt\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install potentially missing packages in SageMaker\n",
    "\n",
    "# import sys\n",
    "# ! {sys.executable} -m pip install tensorflow\n",
    "# ! {sys.executable} -m pip install shap\n",
    "# ! {sys.executable} -m pip install keras\n",
    "# ! {sys.executable} -m pip install graphviz\n",
    "# ! {sys.executable} -m pip install pyathena\n",
    "# ! {sys.executable} -m pip install snappy\n",
    "# ! {sys.executable} -m pip install xgboost\n",
    "# ! {sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import sys\n",
    "import pyarrow\n",
    "import snappy\n",
    "import graphviz\n",
    "\n",
    "from itertools import chain\n",
    "from functools import reduce\n",
    "from pyathena import connect\n",
    "from os import path\n",
    "\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing S3 Data Directory\n",
    "\n",
    "data_dir = 's3://cotezach-prod/TRON_Bypass_Modelling/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Directly Query Athena Tables\n",
    "\n",
    "def athena_conn(query, s3_dir = 's3://aws-athena-query-results-038954691342-us-east-1/', region = 'us-east-1'):\n",
    "    \"\"\"Return a SQL query from Athena into a pandas dataframe.\"\"\"\n",
    "    \n",
    "    # Define connection to Athena\n",
    "    conn = connect(s3_staging_dir = s3_dir,\n",
    "                   region_name = region)\n",
    "    \n",
    "    # Query Athena and return to df\n",
    "    df = pd.read_sql(query, conn)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch from / Write to S3 Functions\n",
    "\n",
    "def fetch_s3_from_file(path_to_file):\n",
    "    \n",
    "    client = boto3.client('s3')\n",
    "    obj2 = client.get_object(Bucket = 'cotezach-prod', Key = path_to_file)\n",
    "    df = pd.read_csv(obj2['Body'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_results_s3(dataframe, sand_box, path):\n",
    "    data_string = dataframe.to_csv()\n",
    "    resource = boto3.resource('s3')\n",
    "    object = resource.Object(sand_box, path) # Select folder and file name in your path in S3\n",
    "    object.put(Body = data_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Site Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying Building Information\n",
    "\n",
    "query = '''\n",
    "\n",
    "-- Building Information\n",
    "\n",
    "WITH fc_info as (\n",
    "            SELECT\n",
    "             fc.warehouse AS building\n",
    "            ,fc.region as region\n",
    "            ,fc.timezone AS time_zone\n",
    "            ,fc.building_type\n",
    "            ,SPLIT_PART(z.drive_type,'-',2) as drive_type\n",
    "            FROM ar_metadata.warehouses_v3_prod_v fc\n",
    "            LEFT JOIN ar_metadata.zones_v3_prod_v z ON fc.warehouse = z.warehouse\n",
    "            )\n",
    "            \n",
    "SELECT DISTINCT\n",
    "     fc.building as site\n",
    "    ,fc.region\n",
    "    ,CASE WHEN fc.building_type = 'Gen11' THEN 'GEN11'\n",
    "          WHEN fc.building_type = 'Sub Same Day Prime' THEN 'SSD'\n",
    "          ELSE fc.building_type END as building_type\n",
    "    ,fc.drive_type\n",
    "    ,b.first_pick_data as pick_start\n",
    "    ,b.first_stow_data as stow_start\n",
    "FROM fc_info fc\n",
    "JOIN aggregated_metrics.building_launch_info_v b on fc.building = b.site\n",
    "WHERE 1=1\n",
    "    AND fc.building IS NOT NULL\n",
    "    AND fc.drive_type IS NOT NULL\n",
    "    AND b.first_pick_data IS NOT NULL\n",
    "    AND fc.drive_type IN ('H','G')\n",
    "    AND fc.region IN ('NA','EU','NRT') '''\n",
    "\n",
    "fc_data = athena_conn(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>region</th>\n",
       "      <th>building_type</th>\n",
       "      <th>drive_type</th>\n",
       "      <th>pick_start</th>\n",
       "      <th>launch_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABQ1</td>\n",
       "      <td>NA</td>\n",
       "      <td>GEN11</td>\n",
       "      <td>H</td>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACY1</td>\n",
       "      <td>NA</td>\n",
       "      <td>Sortable</td>\n",
       "      <td>H</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGS1</td>\n",
       "      <td>NA</td>\n",
       "      <td>GEN11</td>\n",
       "      <td>H</td>\n",
       "      <td>2021-08-24</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGS2</td>\n",
       "      <td>NA</td>\n",
       "      <td>Quick Deploy</td>\n",
       "      <td>H</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AKC1</td>\n",
       "      <td>NA</td>\n",
       "      <td>Sortable</td>\n",
       "      <td>H</td>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site region building_type drive_type pick_start  launch_year\n",
       "0  ABQ1     NA         GEN11          H 2021-10-25         2021\n",
       "1  ACY1     NA      Sortable          H 2018-12-29         2018\n",
       "2  AGS1     NA         GEN11          H 2021-08-24         2021\n",
       "3  AGS2     NA  Quick Deploy          H 2020-10-09         2020\n",
       "4  AKC1     NA      Sortable          H 2020-11-04         2020"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = fc_data\n",
    "\n",
    "# Sorting by kiva_system_key & Datetime\n",
    "fc = fc.sort_values(['site','drive_type','building_type','pick_start'], ignore_index = True)\n",
    "\n",
    "# Creating Launch Year\n",
    "fc['pick_start'] = pd.to_datetime(fc['pick_start'])\n",
    "fc['launch_year'] = pd.DatetimeIndex(fc['pick_start']).year\n",
    "\n",
    "# Trimming DF\n",
    "fc = fc[['site','region','building_type','drive_type','pick_start','launch_year']]\n",
    "\n",
    "fc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stow Performance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Querying Stow Rate/Takt Data\n",
    "\n",
    "query = '''\n",
    "\n",
    "-- Daily Stow Rate/Takt by Site\n",
    "\n",
    "WITH fc_info AS (\n",
    "     SELECT \n",
    "         fc.warehouse as building\n",
    "        ,fc.region as region\n",
    "        ,fc.timezone as time_zone\n",
    "     FROM ar_metadata.warehouses_v3_prod_v fc\n",
    "    ),\n",
    "    \n",
    "stow_metrics as (\n",
    "    SELECT s.*\n",
    "    FROM ar_fulfillment.stow_metrics_prod_v s \n",
    "    WHERE 1=1\n",
    "          AND pt_ingestion_date BETWEEN DATE('2022-01-01') AND CURRENT_DATE\n",
    "          -- AND region IN ('NA','EU','NRT')\n",
    "          -- AND station_operating_mode LIKE ('%IDS%')\n",
    "          AND units_stowed > 0\n",
    "          AND logged_milliseconds > 0\n",
    "   ),\n",
    "   \n",
    "tenure_sub as (\n",
    "\n",
    "-- This query is set ~2 months earlier than the main one above to ensure veteran rates are 100% captured\n",
    "\n",
    "WITH hrs_per_day as(\n",
    "     select\n",
    "       warehouse as building,\n",
    "       pt_ingestion_date as pt_date,\n",
    "       user_id as uid,\n",
    "       sum(logged_milliseconds/3600000.0) logged_hrs\n",
    "     from ar_fulfillment.stow_metrics_prod_v s\n",
    "     where pt_ingestion_date BETWEEN DATE('2021-11-01') AND CURRENT_DATE\n",
    "     -- AND region IN ('NA')\n",
    "     group by 1,2,3\n",
    " \n",
    "), cumulative_hrs_table as (\n",
    "   select\n",
    "     building,\n",
    "     pt_date,\n",
    "     uid,\n",
    "     sum(logged_hrs) over (partition by uid order by pt_date) cumulative_logged_hrs\n",
    "   from hrs_per_day\n",
    ")\n",
    " \n",
    "   SELECT\n",
    "     building,\n",
    "     pt_date,\n",
    "     uid,\n",
    "     CASE WHEN cumulative_logged_hrs >= 160 THEN 'veteran' ELSE 'non' END as tenure\n",
    "   from cumulative_hrs_table )\n",
    "\n",
    "-- MAIN QUERY\n",
    "\n",
    "SELECT\n",
    "    warehouse as site\n",
    "   -- ,zone as floor\n",
    "   ,DATE(from_unixtime(to_unixtime(s.start_time),fc_info.time_zone)) AS pt_fc_date\n",
    "   ,SUM(s.units_stowed*1.0) AS ib_volume\n",
    "   ,SUM(s.logged_milliseconds*1.0/1000.0/3600.0) as stow_hrs\n",
    "   ,SUM(CASE WHEN tenure = 'veteran' THEN s.logged_milliseconds*1.0/1000.0/3600.0 ELSE 0 END) AS vet_hrs\n",
    "   ,SUM(s.work_milliseconds*1.0/1000.0) as stow_work_secs\n",
    "   ,SUM(s.stows_performed_count) as stows_performed\n",
    "   ,SUM(CASE WHEN station_operating_mode LIKE '%IDS%' THEN s.work_milliseconds*1.0/1000.0 ELSE 0 END) AS IDS_work_secs\n",
    "   ,SUM(CASE WHEN station_operating_mode LIKE '%IDS%' THEN s.stows_performed_count ELSE 0 END) AS IDS_stows_performed\n",
    "   ,SUM(NULLIF(pod_faces_count,0)*1.0) as pod_visits\n",
    "   ,SUM(s.units_stowed*1.0)/ SUM(NULLIF(pod_faces_count,0)*1.0) AS units_per_face\n",
    "FROM stow_metrics s\n",
    "JOIN fc_info ON s.warehouse = fc_info.building\n",
    "RIGHT JOIN tenure_sub t ON s.user_id = t.uid\n",
    "GROUP BY 1,2 '''\n",
    "\n",
    "# stow_data = athena_conn(query)\n",
    "\n",
    "# Pulling in the Data from s3\n",
    "stow_data = fetch_s3_from_file('TRON_Bypass_Modelling/stow_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pulling in multiple CSVs from prodna/eu/nrt data sources\n",
    "\n",
    "# stow_na = fetch_s3_from_file('TRON_Bypass_Modelling/stow_metrics_prodna.csv')\n",
    "# stow_eu = fetch_s3_from_file('TRON_Bypass_Modelling/stow_metrics_prodeu.csv')\n",
    "# stow_nrt = fetch_s3_from_file('TRON_Bypass_Modelling/stow_metrics_prodnrt.csv')\n",
    "\n",
    "# Concatenate the Three DFs together\n",
    "# stow_data = pd.concat([stow_na, stow_eu, stow_nrt], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>pt_fc_date</th>\n",
       "      <th>ib_volume</th>\n",
       "      <th>stow_hrs</th>\n",
       "      <th>vet_hrs</th>\n",
       "      <th>stow_work_secs</th>\n",
       "      <th>stows_performed</th>\n",
       "      <th>IDS_work_secs</th>\n",
       "      <th>IDS_stows_performed</th>\n",
       "      <th>pod_visits</th>\n",
       "      <th>units_per_face</th>\n",
       "      <th>tenure_per</th>\n",
       "      <th>ids_takt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-07-24</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.705768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.602306e+04</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.602306e+04</td>\n",
       "      <td>91</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>176.077538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>929513.0</td>\n",
       "      <td>7884.598364</td>\n",
       "      <td>4335.538396</td>\n",
       "      <td>3.460000e+07</td>\n",
       "      <td>929513.0</td>\n",
       "      <td>3.460000e+07</td>\n",
       "      <td>929513</td>\n",
       "      <td>125281.000005</td>\n",
       "      <td>7.419425</td>\n",
       "      <td>54.987435</td>\n",
       "      <td>37.223794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-07-26</td>\n",
       "      <td>2205647.0</td>\n",
       "      <td>18385.576740</td>\n",
       "      <td>9893.401619</td>\n",
       "      <td>6.670000e+07</td>\n",
       "      <td>2205647.0</td>\n",
       "      <td>6.670000e+07</td>\n",
       "      <td>2205647</td>\n",
       "      <td>402150.000003</td>\n",
       "      <td>5.484638</td>\n",
       "      <td>53.810668</td>\n",
       "      <td>30.240560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-07-27</td>\n",
       "      <td>2347255.0</td>\n",
       "      <td>18709.798650</td>\n",
       "      <td>9649.500594</td>\n",
       "      <td>6.550000e+07</td>\n",
       "      <td>2347255.0</td>\n",
       "      <td>6.550000e+07</td>\n",
       "      <td>2347255</td>\n",
       "      <td>491475.999958</td>\n",
       "      <td>4.775930</td>\n",
       "      <td>51.574583</td>\n",
       "      <td>27.904936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>666783.0</td>\n",
       "      <td>6950.693949</td>\n",
       "      <td>2555.934894</td>\n",
       "      <td>2.560000e+07</td>\n",
       "      <td>666783.0</td>\n",
       "      <td>2.560000e+07</td>\n",
       "      <td>666783</td>\n",
       "      <td>144057.999987</td>\n",
       "      <td>4.628573</td>\n",
       "      <td>36.772370</td>\n",
       "      <td>38.393300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    site pt_fc_date  ib_volume      stow_hrs      vet_hrs  stow_work_secs  \\\n",
       "0  1-Jan 2022-07-24       91.0      2.705768     0.000000    1.602306e+04   \n",
       "1  1-Jan 2022-07-25   929513.0   7884.598364  4335.538396    3.460000e+07   \n",
       "2  1-Jan 2022-07-26  2205647.0  18385.576740  9893.401619    6.670000e+07   \n",
       "3  1-Jan 2022-07-27  2347255.0  18709.798650  9649.500594    6.550000e+07   \n",
       "4  1-Jan 2022-07-28   666783.0   6950.693949  2555.934894    2.560000e+07   \n",
       "\n",
       "   stows_performed  IDS_work_secs  IDS_stows_performed     pod_visits  \\\n",
       "0             91.0   1.602306e+04                   91      63.000000   \n",
       "1         929513.0   3.460000e+07               929513  125281.000005   \n",
       "2        2205647.0   6.670000e+07              2205647  402150.000003   \n",
       "3        2347255.0   6.550000e+07              2347255  491475.999958   \n",
       "4         666783.0   2.560000e+07               666783  144057.999987   \n",
       "\n",
       "   units_per_face  tenure_per    ids_takt  \n",
       "0        1.444444    0.000000  176.077538  \n",
       "1        7.419425   54.987435   37.223794  \n",
       "2        5.484638   53.810668   30.240560  \n",
       "3        4.775930   51.574583   27.904936  \n",
       "4        4.628573   36.772370   38.393300  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stow = stow_data\n",
    "\n",
    "# Setting pt_fc_date as Datetime\n",
    "stow['pt_fc_date'] = pd.to_datetime(stow['pt_fc_date'])\n",
    "\n",
    "# Sorting by kiva_system_key & Datetime\n",
    "stow = stow.sort_values(['site','pt_fc_date'], ignore_index = True)\n",
    "\n",
    "# Calc Key KPIs (tenure is considered LC5+ associates, >160 Stow hours logged)\n",
    "stow['pod_visits'] = stow['ib_volume'] / stow['units_per_face']\n",
    "stow['tenure_per'] = stow['vet_hrs'] / stow['stow_hrs'] *100\n",
    "stow['ids_takt'] = stow['IDS_work_secs'] / stow['IDS_stows_performed']\n",
    "\n",
    "stow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4431/676053895.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stow' is not defined"
     ]
    }
   ],
   "source": [
    "stow.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDS-Specific Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Querying IDS Metrics (TBR, ME DPMO, etc.)\n",
    "\n",
    "query = '''\n",
    "    \n",
    "-- NACF & EUCF Query\n",
    " \n",
    "select\n",
    "    n.building,\n",
    "    -- n.floor,\n",
    "    n.pt_date as pt_fc_date,\n",
    "    SUM(n.stow_resolutions)*1.0 as total_stows,\n",
    "    SUM(tron_high_confidence_agreements)*1.0 as hc_agreements,\n",
    "    SUM(tron_high_confidence_agreements)*1.0/nullif(SUM(tron_high_confidence_audits)*1.0,0) as ml_accuracy,\n",
    "    SUM(tron_high_confidence_audits)*1.0 as hc_audits,\n",
    "    SUM(high_confidence_count)*1.0 as hc_count,\n",
    "    SUM(tron_low_confidence_agreements)*1.0 as lc_agreements,\n",
    "    SUM(tron_low_confidence_audits)*1.0 as lc_audits,\n",
    "    SUM(low_confidence_count)*1.0 as lc_count,\n",
    "    SUM(multiple_events)*1.0 as multiple_events,\n",
    "    SUM(negative_stow_hint_violations)*1.0 as negative_stow_hint_violations\n",
    "from aggregated_metrics_nike.ids_5min_aggregated_metrics_v n\n",
    "where n.pt_date BETWEEN DATE('2022-01-01') AND CURRENT_DATE\n",
    "group by 1,2\n",
    " \n",
    "UNION ALL\n",
    " \n",
    "-- NRT Query\n",
    " \n",
    "select\n",
    "    n.building,\n",
    "    -- n.floor,\n",
    "    n.pt_date as pt_fc_date,\n",
    "    SUM(n.stow_resolutions)*1.0 as total_stows,\n",
    "    SUM(tron_high_confidence_agreements)*1.0 as hc_agreements,\n",
    "    SUM(tron_high_confidence_agreements)*1.0/nullif(SUM(tron_high_confidence_audits)*1.0,0) as ml_accuracy,\n",
    "    SUM(tron_high_confidence_audits)*1.0 as hc_audits,\n",
    "    SUM(high_confidence_count)*1.0 as hc_count,\n",
    "    SUM(tron_low_confidence_agreements)*1.0 as lc_agreements,\n",
    "    SUM(tron_low_confidence_audits)*1.0 as lc_audits,\n",
    "    SUM(low_confidence_count)*1.0 as lc_count,\n",
    "    SUM(multiple_events)*1.0 as multiple_events,\n",
    "    SUM(negative_stow_hint_violations)*1.0 as negative_stow_hint_violations\n",
    "from aggregated_metrics_nike.ids_5min_aggregated_metrics_nrt_v n\n",
    "where n.pt_date BETWEEN DATE('2022-01-01') AND CURRENT_DATE\n",
    "group by 1,2 '''\n",
    "\n",
    "# ids_data = athena_conn(query)\n",
    "\n",
    "# Pulling in the Data from s3\n",
    "ids_data = fetch_s3_from_file('TRON_Bypass_Modelling/ids_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ids_data\n",
    "\n",
    "# Setting pt_fc_date as Datetime\n",
    "ids['pt_fc_date'] = pd.to_datetime(ids['pt_fc_date'])\n",
    "\n",
    "# Renaming Building to Site\n",
    "ids = ids.rename(columns={\"building\": \"site\"})\n",
    "\n",
    "# Sorting by kiva_system_key & Datetime\n",
    "ids = ids.sort_values(['site','pt_fc_date'], ignore_index = True)\n",
    "\n",
    "# Calc Key KPIs\n",
    "ids['tron_bypass_rate'] = ids['hc_count'] / ids['total_stows']\n",
    "ids['tron_ioa'] = ids['lc_agreements'] / ids['lc_audits']\n",
    "ids['me_dpmo'] = ids['multiple_events'] / ids['total_stows'] *1000000\n",
    "ids['ml_accuracy'] = ids['ML_Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing Missing Values using Nike Program Standards\n",
    "ids['ml_accuracy'].fillna(0.999, inplace = True)\n",
    "ids['tron_ioa'].fillna(0.993, inplace = True)\n",
    "\n",
    "# Recalculating Ids System Accuracy with Imputed Values\n",
    "ids['ids_accuracy'] = (ids['tron_bypass_rate'] * ids['ml_accuracy'] + (1 - ids['tron_bypass_rate']) * \n",
    "                       ids['tron_ioa'] - ids['me_dpmo']/1000000) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>pt_fc_date</th>\n",
       "      <th>total_stows</th>\n",
       "      <th>hc_agreements</th>\n",
       "      <th>ML_Accuracy</th>\n",
       "      <th>hc_audits</th>\n",
       "      <th>hc_count</th>\n",
       "      <th>lc_agreements</th>\n",
       "      <th>lc_audits</th>\n",
       "      <th>lc_count</th>\n",
       "      <th>multiple_events</th>\n",
       "      <th>tron_bypass_rate</th>\n",
       "      <th>tron_ioa</th>\n",
       "      <th>me_dpmo</th>\n",
       "      <th>ml_accuracy</th>\n",
       "      <th>ids_accuracy</th>\n",
       "      <th>me_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>99.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>99.600000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>99.985714</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>97.974000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>13.698630</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>99.986301</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-07-11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>99.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>99.400000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    site pt_fc_date  total_stows  hc_agreements  ML_Accuracy  hc_audits  \\\n",
       "0  1-Jan 2022-06-21            2              0          NaN          0   \n",
       "1  1-Jan 2022-06-27           14              0          NaN          0   \n",
       "2  1-Jan 2022-06-28           50              0          NaN          0   \n",
       "3  1-Jan 2022-06-29           73              0          NaN          0   \n",
       "4  1-Jan 2022-07-11            6              0          NaN          0   \n",
       "\n",
       "   hc_count  lc_agreements  lc_audits  lc_count  multiple_events  \\\n",
       "0         1              0          0         1                0   \n",
       "1         2              1          1        12                0   \n",
       "2        13              2          2        37                1   \n",
       "3        10              1          1        63                0   \n",
       "4         1              0          0         5                0   \n",
       "\n",
       "   tron_bypass_rate  tron_ioa  me_dpmo  ml_accuracy  ids_accuracy  me_pct  \n",
       "0         50.000000      99.3      0.0         99.9     99.600000     0.0  \n",
       "1         14.285714     100.0      0.0         99.9     99.985714     0.0  \n",
       "2         26.000000     100.0  20000.0         99.9     97.974000     2.0  \n",
       "3         13.698630     100.0      0.0         99.9     99.986301     0.0  \n",
       "4         16.666667      99.3      0.0         99.9     99.400000     0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling all IDS % KPIs up by 100 for Modelling\n",
    "\n",
    "ids['tron_bypass_rate'] = ids['tron_bypass_rate'] *100\n",
    "ids['tron_ioa'] = ids['tron_ioa'] *100\n",
    "ids['ml_accuracy'] = ids['ml_accuracy'] *100\n",
    "ids['me_pct'] = ids['multiple_events'] / ids['total_stows'] *100 # Creating a more stable ME % metric\n",
    "\n",
    "ids.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site Fullness & ASIN Size Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Querying GCU & ACU\n",
    "\n",
    "query = '''\n",
    "\n",
    "-- Daily GCU & ACU by Site\n",
    " \n",
    "WITH fc_info AS (\n",
    "     SELECT \n",
    "         fc.warehouse as building\n",
    "        ,fc.region as region\n",
    "        ,fc.timezone as time_zone\n",
    "     FROM ar_metadata.warehouses_v3_prod_v fc\n",
    "    ),\n",
    " \n",
    "dedup_check as (\n",
    "SELECT \n",
    "     a.warehouse\n",
    "     ,zone\n",
    "     ,snapshot_time\n",
    "     ,DATE(at_timezone(snapshot_time, fc_info.time_zone)) pt_fc_date\n",
    "     ,AVG(bins) bins\n",
    "     ,AVG(units) units\n",
    "     ,AVG(gross_volume_mm_cubed) gross_volume_in_cubed\n",
    "     ,AVG(inventory_volume_mm_cubed) inventory_volume_in_cubed\n",
    "     ,AVG(target_utilization_percent) target_cubic_utilization\n",
    "     FROM ar_fulfillment.inventory_metrics_prod_v a\n",
    "     JOIN fc_info ON a.warehouse = fc_info.building     \n",
    "     WHERE 1=1\n",
    "     and pt_ingestion_date BETWEEN DATE('2022-01-01') AND CURRENT_DATE\n",
    "     and bin_template <> 'PALLET-SINGLE'\n",
    "     and gross_volume_mm_cubed > 0\n",
    "     group by 1,2,3,4 \n",
    "     ),\n",
    "     \n",
    "snapshot_level AS (\n",
    "SELECT \n",
    "    warehouse\n",
    "    ,zone\n",
    "    ,snapshot_time\n",
    "    ,pt_fc_date\n",
    "    ,SUM(bins) bins\n",
    "    ,SUM(units) units\n",
    "    ,SUM(gross_volume_in_cubed) gross_volume\n",
    "    ,SUM(inventory_volume_in_cubed) inventory_volume\n",
    "    FROM dedup_check\n",
    "    GROUP BY 1,2,3,4\n",
    "    ),\n",
    "\n",
    "capacity_metrics AS (\n",
    "SELECT\n",
    "     warehouse as site\n",
    "    ,zone\n",
    "    ,pt_fc_date\n",
    "    ,FLOOR(AVG(bins)) bins\n",
    "    ,FLOOR(AVG(units)) units\n",
    "    ,AVG(gross_volume) gross_volume\n",
    "    ,AVG(inventory_volume) inventory_volume\n",
    "    FROM snapshot_level\n",
    "    GROUP BY 1,2,3\n",
    "    )\n",
    "    \n",
    "-- MAIN QUERY\n",
    "\n",
    "SELECT \n",
    "     site\n",
    "    -- ,floor\n",
    "    ,pt_fc_date\n",
    "    ,SUM(units) units\n",
    "    ,SUM(bins) bins\n",
    "    ,SUM(inventory_volume*1.0) AS inventory_volume\n",
    "    ,SUM(gross_volume*1.0) AS gross_volume\n",
    "    ,100.0*SUM(inventory_volume*1.0)/SUM(gross_volume*1.0) gcu\n",
    "    ,1.0*SUM(inventory_volume*1.0)/(12*12*12)/SUM(units) acu\n",
    "FROM capacity_metrics\n",
    "GROUP BY 1,2 '''\n",
    "\n",
    "# gcu_data = athena_conn(query)\n",
    "\n",
    "# Pulling in the Data from s3\n",
    "gcu_data = fetch_s3_from_file('TRON_Bypass_Modelling/gcu_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pulling in multiple CSVs from prodna/eu/nrt data sources\n",
    "\n",
    "# gcu_na = fetch_s3_from_file('TRON_Bypass_Modelling/gcu_metrics_prodna.csv')\n",
    "# gcu_eu = fetch_s3_from_file('TRON_Bypass_Modelling/gcu_metrics_prodeu.csv')\n",
    "# gcu_nrt = fetch_s3_from_file('TRON_Bypass_Modelling/gcu_metrics_prodnrt.csv')\n",
    "\n",
    "# Concatenate the Three DFs together\n",
    "# gcu_data = pd.concat([gcu_na, gcu_eu, gcu_nrt], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>pt_fc_date</th>\n",
       "      <th>units</th>\n",
       "      <th>bins</th>\n",
       "      <th>inventory_volume</th>\n",
       "      <th>gross_volume</th>\n",
       "      <th>gcu</th>\n",
       "      <th>acu</th>\n",
       "      <th>units_per_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABQ1</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>1495631.0</td>\n",
       "      <td>621114.0</td>\n",
       "      <td>2.118180e+08</td>\n",
       "      <td>7.270151e+08</td>\n",
       "      <td>29.135290</td>\n",
       "      <td>141.624484</td>\n",
       "      <td>2.407981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABQ1</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1495863.0</td>\n",
       "      <td>621114.0</td>\n",
       "      <td>2.118493e+08</td>\n",
       "      <td>7.270151e+08</td>\n",
       "      <td>29.139595</td>\n",
       "      <td>141.623440</td>\n",
       "      <td>2.408355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABQ1</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>1498728.0</td>\n",
       "      <td>621114.0</td>\n",
       "      <td>2.123313e+08</td>\n",
       "      <td>7.270151e+08</td>\n",
       "      <td>29.205901</td>\n",
       "      <td>141.674353</td>\n",
       "      <td>2.412968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABQ1</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>1508610.0</td>\n",
       "      <td>621114.0</td>\n",
       "      <td>2.140954e+08</td>\n",
       "      <td>7.270151e+08</td>\n",
       "      <td>29.448547</td>\n",
       "      <td>141.915666</td>\n",
       "      <td>2.428878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABQ1</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>1520291.0</td>\n",
       "      <td>621114.0</td>\n",
       "      <td>2.162039e+08</td>\n",
       "      <td>7.270151e+08</td>\n",
       "      <td>29.738573</td>\n",
       "      <td>142.212202</td>\n",
       "      <td>2.447684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site pt_fc_date      units      bins  inventory_volume  gross_volume  \\\n",
       "0  ABQ1 2021-12-31  1495631.0  621114.0      2.118180e+08  7.270151e+08   \n",
       "1  ABQ1 2022-01-01  1495863.0  621114.0      2.118493e+08  7.270151e+08   \n",
       "2  ABQ1 2022-01-02  1498728.0  621114.0      2.123313e+08  7.270151e+08   \n",
       "3  ABQ1 2022-01-03  1508610.0  621114.0      2.140954e+08  7.270151e+08   \n",
       "4  ABQ1 2022-01-04  1520291.0  621114.0      2.162039e+08  7.270151e+08   \n",
       "\n",
       "         gcu         acu  units_per_bin  \n",
       "0  29.135290  141.624484       2.407981  \n",
       "1  29.139595  141.623440       2.408355  \n",
       "2  29.205901  141.674353       2.412968  \n",
       "3  29.448547  141.915666       2.428878  \n",
       "4  29.738573  142.212202       2.447684  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcu = gcu_data\n",
    "\n",
    "# Setting pt_fc_date as Datetime\n",
    "gcu['pt_fc_date'] = pd.to_datetime(gcu['pt_fc_date'])\n",
    "\n",
    "# Sorting by kiva_system_key & Datetime\n",
    "gcu = gcu.sort_values(['site','pt_fc_date'], ignore_index = True)\n",
    "\n",
    "# Converting ACU to Cubic Inches (from Cubic Feet)\n",
    "gcu['acu'] = gcu['acu'] * (12*12*12)\n",
    "\n",
    "# Calc Units per Bin\n",
    "gcu['units_per_bin'] = gcu['units'] / gcu['bins']\n",
    "\n",
    "gcu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site Podgap Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Querying Podgap\n",
    "\n",
    "query = '''\n",
    "\n",
    "-- Stow Podgap\n",
    " \n",
    "WITH fc_info AS (\n",
    "     SELECT \n",
    "         fc.warehouse as building\n",
    "        ,fc.region as region\n",
    "        ,fc.timezone as time_zone\n",
    "     FROM ar_metadata.warehouses_v3_prod_v fc\n",
    "    ),\n",
    "    \n",
    "pod_gap as (\n",
    "    SELECT s.*\n",
    "    FROM ar_fulfillment.pod_gap_metrics_prod_v s \n",
    "    WHERE 1=1\n",
    "          AND pt_ingestion_date BETWEEN DATE('2022-01-01') AND CURRENT_DATE\n",
    "          AND station_operating_mode LIKE ('%Stow%')\n",
    "          -- AND region IN ('NA')\n",
    "   )\n",
    " \n",
    "-- MAIN QUERY\n",
    " \n",
    "SELECT\n",
    "    warehouse as site\n",
    "   -- ,zone as floor\n",
    "   ,DATE(from_unixtime(to_unixtime(s.start_time),fc_info.time_zone)) AS pt_fc_date\n",
    "   ,SUM(s.gap_time_milliseconds*1.0) AS stow_gap_ms\n",
    "   ,SUM(s.gap_time_milliseconds + s.ramp_up_time_milliseconds + s.dwell_time_milliseconds + s.transition_time_milliseconds) AS stow_total_ms     \n",
    "FROM pod_gap s\n",
    "JOIN fc_info ON s.warehouse = fc_info.building\n",
    "GROUP BY 1,2 '''\n",
    "\n",
    "# pg_data = athena_conn(query)\n",
    "\n",
    "# Pulling in the Data from s3\n",
    "pg_data = fetch_s3_from_file('TRON_Bypass_Modelling/podgap_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pulling in multiple CSVs from prodna/eu/nrt data sources\n",
    "\n",
    "# pg_na = fetch_s3_from_file('TRON_Bypass_Modelling/podgap_metrics_prodna.csv')\n",
    "# pg_eu = fetch_s3_from_file('TRON_Bypass_Modelling/podgap_metrics_prodeu.csv')\n",
    "# pg_nrt = fetch_s3_from_file('TRON_Bypass_Modelling/podgap_metrics_prodnrt.csv')\n",
    "\n",
    "# Concatenate the Three DFs together\n",
    "# pg_data = pd.concat([pg_na, pg_eu, pg_nrt], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>pt_fc_date</th>\n",
       "      <th>stow_gap_ms</th>\n",
       "      <th>stow_total_ms</th>\n",
       "      <th>stowgap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-06-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>716695.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>948065.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>38615.0</td>\n",
       "      <td>1000856.0</td>\n",
       "      <td>3.858197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-06-16</td>\n",
       "      <td>334811.0</td>\n",
       "      <td>4099128.0</td>\n",
       "      <td>8.167859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-Jan</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>98484.0</td>\n",
       "      <td>8157976.0</td>\n",
       "      <td>1.207211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    site pt_fc_date  stow_gap_ms  stow_total_ms   stowgap\n",
       "0  1-Jan 2022-06-09          0.0       716695.0  0.000000\n",
       "1  1-Jan 2022-06-10          0.0       948065.0  0.000000\n",
       "2  1-Jan 2022-06-15      38615.0      1000856.0  3.858197\n",
       "3  1-Jan 2022-06-16     334811.0      4099128.0  8.167859\n",
       "4  1-Jan 2022-06-17      98484.0      8157976.0  1.207211"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podgap = pg_data\n",
    "\n",
    "# Setting pt_fc_date as Datetime\n",
    "podgap['pt_fc_date'] = pd.to_datetime(podgap['pt_fc_date'])\n",
    "\n",
    "# Sorting by kiva_system_key & Datetime\n",
    "podgap = podgap.sort_values(['site','pt_fc_date'], ignore_index = True)\n",
    "\n",
    "# Calculating Podgap Percentage\n",
    "podgap['stowgap'] = podgap['stow_gap_ms'] / podgap['stow_total_ms'] *100\n",
    "\n",
    "podgap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging All Data Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['site', 'pt_fc_date', 'total_stows', 'hc_agreements', 'ML_Accuracy',\n",
       "       'hc_audits', 'hc_count', 'lc_agreements', 'lc_audits', 'lc_count',\n",
       "       'multiple_events', 'tron_bypass_rate', 'tron_ioa', 'me_dpmo',\n",
       "       'ml_accuracy', 'ids_accuracy', 'me_pct', 'ib_volume', 'stow_hrs',\n",
       "       'vet_hrs', 'stow_work_secs', 'stows_performed', 'IDS_work_secs',\n",
       "       'IDS_stows_performed', 'pod_visits', 'units_per_face', 'tenure_per',\n",
       "       'ids_takt', 'stow_gap_ms', 'stow_total_ms', 'stowgap', 'units', 'bins',\n",
       "       'inventory_volume', 'gross_volume', 'gcu', 'acu', 'units_per_bin',\n",
       "       'region', 'building_type', 'drive_type', 'pick_start', 'launch_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main DF is going to be the IDS Dataframe\n",
    "main_df = ids\n",
    "\n",
    "# Merging in all other KPIs\n",
    "kpi_dfs = [main_df, stow, podgap, gcu] \n",
    "main_df = reduce(lambda left, right: pd.merge(left, right, on = ['site','pt_fc_date'], how = 'outer'), kpi_dfs)\n",
    "\n",
    "# Merging with FC_INFO (for Drive Type & Region)\n",
    "main_df = pd.merge(main_df, fc, how = 'left', on = ['site'])\n",
    "\n",
    "main_df.columns.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ABQ1', 'ACY1', 'AGS1', 'AGS2', 'AKC1', 'ATL2', 'AUS2', 'AUS3',\n",
       "       'BCN1', 'BCN4', 'BDL2', 'BDL3', 'BDL4', 'BFI1', 'BFI4', 'BFL1',\n",
       "       'BGY1', 'BHM1', 'BLQ1', 'BOI2', 'BRE4', 'BRQ2', 'BRS1', 'BRS2',\n",
       "       'BWI2', 'BWU2', 'CLE2', 'CLE3', 'CLT4', 'CMH1', 'CMH4', 'DAL3',\n",
       "       'DCA1', 'DEN3', 'DEN4', 'DET3', 'DET6', 'DFW7', 'DSA6', 'DSM5',\n",
       "       'DTW1', 'DUS4', 'ELP1', 'EMA1', 'EMA2', 'ETZ2', 'EWR4', 'EWR9',\n",
       "       'FAT1', 'FCO1', 'FRA7', 'FSD1', 'FTW6', 'FWA6', 'GEG1', 'GRR1',\n",
       "       'GYR1', 'HAM2', 'HND6', 'HOU2', 'HOU6', 'IAH1', 'IGQ1', 'JAX2',\n",
       "       'JFK8', 'KIX3', 'KIX5', 'KIX6', 'KTW3', 'LAS7', 'LCY2', 'LCY3',\n",
       "       'LEJ5', 'LGA9', 'LGB3', 'LGB7', 'LIT1', 'LTN4', 'MAD7', 'MAN1',\n",
       "       'MAN2', 'MAN3', 'MCO1', 'MDW7', 'MEM4', 'MIA1', 'MKC6', 'MKE1',\n",
       "       'MKE2', 'MME1', 'MME2', 'MQY1', 'MSP1', 'MTN1', 'MUC3', 'MXP6',\n",
       "       'NCL1', 'NCL2', 'NUE1', 'OAK4', 'OKC1', 'ORD5', 'ORF3', 'ORY4',\n",
       "       'OVD1', 'OXR1', 'PAD1', 'PCW1', 'PDX9', 'POZ2', 'PSP1', 'PSR2',\n",
       "       'QCB1', 'RDU1', 'RMU1', 'SAN3', 'SAT2', 'SAX2', 'SAX3', 'SAZ1',\n",
       "       'SCA3', 'SCA4', 'SCA5', 'SCK6', 'SCN2', 'SCO1', 'SDC1', 'SES1',\n",
       "       'SFL1', 'SFL2', 'SFL3', 'SFL4', 'SGA1', 'SGA2', 'SIL1', 'SIL2',\n",
       "       'SIL3', 'SIN9', 'SLC1', 'SMA2', 'SMD1', 'SMF1', 'SMI1', 'SMN1',\n",
       "       'SMO2', 'SNC2', 'SNC3', 'SNJ1', 'SNJ3', 'SNV1', 'SNY5', 'SOH1',\n",
       "       'SOH2', 'SOH3', 'STL8', 'STN1', 'STX2', 'STX3', 'STX4', 'STX5',\n",
       "       'STX6', 'STX7', 'SUT1', 'SVQ1', 'SWA1', 'SWA2', 'SWI1', 'SYR1',\n",
       "       'SZZ1', 'TPA1', 'TPA4', 'TRN1', 'TUL2', 'TUS2', 'TYO1', 'TYO4',\n",
       "       'TYO6', 'TYO7', 'TYO8', 'TYO9', 'VGT1', 'YHM1', 'YOW3', 'YUL2',\n",
       "       'YXX2', 'YYZ4', 'YYZ9', 'FTW4', 'MGE7', 'SAX1', 'SAZ2', 'SMO1',\n",
       "       'SOR3', 'JAN1'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trimming Main Df to just applicable Sites, Drive Types\n",
    "main_df = main_df[main_df['building_type'].isin(['GEN11','Sortable','SSD','Quick Deploy'])]\n",
    "main_df = main_df[main_df['drive_type'].isin(['H','G'])]\n",
    "\n",
    "# Creating Maturity Binary Field (120 Days Since First Pick)\n",
    "main_df['site_maturity'] = ((main_df['pt_fc_date'] - main_df['pick_start']).dt.days >= 120)*1\n",
    "\n",
    "# What Buildings are Present?\n",
    "main_df.site.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Percentages by Column\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "site                    0.000000\n",
       "pt_fc_date              0.000000\n",
       "total_stows             8.452682\n",
       "hc_agreements           8.452682\n",
       "ML_Accuracy            10.128952\n",
       "hc_audits               8.452682\n",
       "hc_count                8.452682\n",
       "lc_agreements           8.452682\n",
       "lc_audits               8.452682\n",
       "lc_count                8.452682\n",
       "multiple_events         8.452682\n",
       "tron_bypass_rate        8.452682\n",
       "tron_ioa                8.452682\n",
       "me_dpmo                 8.452682\n",
       "ml_accuracy             8.452682\n",
       "ids_accuracy            8.452682\n",
       "me_pct                  8.452682\n",
       "ib_volume               7.279070\n",
       "stow_hrs                7.279070\n",
       "vet_hrs                 7.279070\n",
       "stow_work_secs          7.279070\n",
       "stows_performed         7.279070\n",
       "IDS_work_secs           7.279070\n",
       "IDS_stows_performed     7.279070\n",
       "pod_visits              7.281299\n",
       "units_per_face          7.281299\n",
       "tenure_per              7.279070\n",
       "ids_takt                8.756952\n",
       "stow_gap_ms             4.785841\n",
       "stow_total_ms           4.785841\n",
       "stowgap                 4.785841\n",
       "units                   0.153807\n",
       "bins                    0.153807\n",
       "inventory_volume        0.153807\n",
       "gross_volume            0.153807\n",
       "gcu                     0.153807\n",
       "acu                     0.390089\n",
       "units_per_bin           0.153807\n",
       "region                  0.000000\n",
       "building_type           0.000000\n",
       "drive_type              0.000000\n",
       "pick_start              0.000000\n",
       "launch_year             0.000000\n",
       "site_maturity           0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Null % within each Column of the Export Dataframe\n",
    "\n",
    "# Expanding # of Rows to be shown\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "print(\"Null Percentages by Column\")\n",
    "main_df.isnull().sum(axis = 0)/len(main_df) *100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Exporting the Dataframe for Use in the Model Notebook\n",
    "\n",
    "write_results_s3(main_df,'cotezach-prod','TRON_Bypass_Modelling/TBR_model_data_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
